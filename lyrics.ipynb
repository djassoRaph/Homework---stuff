{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lyrics classifier. Trying to get the mood out of the song. \n",
    "\n",
    "Import the MasterSong.json file first..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df = pd.read_json('MasterSongList.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics_features</th>\n",
       "      <th>moods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[oppa, gangnam, style, gangnam, style, najeneu...</td>\n",
       "      <td>[energetic, motivational]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[lately, i, ve, been, i, ve, been, losing, sle...</td>\n",
       "      <td>[happy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[party, rock, yeah, woo, let, s, go, party, ro...</td>\n",
       "      <td>[happy, celebratory, rowdy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[alagamun, lan, weh, wakun, heya, hanun, gon, ...</td>\n",
       "      <td>[happy, energetic, celebratory]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[j, lo, the, other, side, out, my, mine, it, s...</td>\n",
       "      <td>[energetic]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     lyrics_features  \\\n",
       "0  [oppa, gangnam, style, gangnam, style, najeneu...   \n",
       "1  [lately, i, ve, been, i, ve, been, losing, sle...   \n",
       "2  [party, rock, yeah, woo, let, s, go, party, ro...   \n",
       "3  [alagamun, lan, weh, wakun, heya, hanun, gon, ...   \n",
       "4  [j, lo, the, other, side, out, my, mine, it, s...   \n",
       "\n",
       "                             moods  \n",
       "0        [energetic, motivational]  \n",
       "1                          [happy]  \n",
       "2      [happy, celebratory, rowdy]  \n",
       "3  [happy, energetic, celebratory]  \n",
       "4                      [energetic]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_lf_m = ['lyrics_features', 'moods']\n",
    "lyrics_df = songs_df.copy()\n",
    "lyrics_df = lyrics_df[songs_lf_m]\n",
    "lyrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df['lyrics_features'] = lyrics_df['lyrics_features'].apply(' '.join)\n",
    "lyrics_df['moods'] = lyrics_df['moods'].apply(', '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics_features</th>\n",
       "      <th>moods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oppa gangnam style gangnam style najeneun ttas...</td>\n",
       "      <td>energetic, motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lately i ve been i ve been losing sleep dreami...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>party rock yeah woo let s go party rock is in ...</td>\n",
       "      <td>happy, celebratory, rowdy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alagamun lan weh wakun heya hanun gon alagamun...</td>\n",
       "      <td>happy, energetic, celebratory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j lo the other side out my mine it s a new gen...</td>\n",
       "      <td>energetic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     lyrics_features  \\\n",
       "0  oppa gangnam style gangnam style najeneun ttas...   \n",
       "1  lately i ve been i ve been losing sleep dreami...   \n",
       "2  party rock yeah woo let s go party rock is in ...   \n",
       "3  alagamun lan weh wakun heya hanun gon alagamun...   \n",
       "4  j lo the other side out my mine it s a new gen...   \n",
       "\n",
       "                           moods  \n",
       "0        energetic, motivational  \n",
       "1                          happy  \n",
       "2      happy, celebratory, rowdy  \n",
       "3  happy, energetic, celebratory  \n",
       "4                      energetic  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NaN songs.\n",
    "lyrics_df['lyrics_features'].replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36733, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df.dropna(subset=['lyrics_features'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20931, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reindex dataframe\n",
    "lyrics_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lyrics classifier. Trying to get the mood out of the song. \n",
    "First I must clean the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Converting everything to lower case\n",
    "2. Removing punctuation\n",
    "3. Removing common words (stop words)\n",
    "4. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(raw_text):\n",
    "    # Create empty list to receive result\n",
    "    clean_words = []\n",
    "    \n",
    "    # 1. Convert to lower case\n",
    "    raw_text = raw_text.lower()\n",
    "    \n",
    "    # 2. Remove punctuation\n",
    "    translator = str.maketrans('', '', punctuation)\n",
    "    raw_text = raw_text.translate(translator)\n",
    "    split_words = raw_text.split()\n",
    "    \n",
    "    # 3 & 4. Remove common words and stem words\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    for word in split_words:\n",
    "        if word not in ENGLISH_STOP_WORDS:\n",
    "            stemmed_word = stemmer.stem(word)\n",
    "            clean_words.append(stemmed_word)\n",
    "            \n",
    "    return ' '.join(clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "songs_df['lyrics_features']=[\" \".join(lyrics_features) for lyrics_features in songs_df['lyrics_features'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aggressive',\n",
       " 'angsty',\n",
       " 'atmospheric',\n",
       " 'campy',\n",
       " 'celebratory',\n",
       " 'classy',\n",
       " 'cocky',\n",
       " 'cold',\n",
       " 'earthy',\n",
       " 'energetic',\n",
       " 'funky',\n",
       " 'gloomy',\n",
       " 'happy',\n",
       " 'hypnotic',\n",
       " 'introspective',\n",
       " 'lush',\n",
       " 'mellow',\n",
       " 'motivational',\n",
       " 'nocturnal',\n",
       " 'raw',\n",
       " 'rowdy',\n",
       " 'sad',\n",
       " 'seductive',\n",
       " 'sexual',\n",
       " 'soothing',\n",
       " 'spacey',\n",
       " 'sprightly',\n",
       " 'sweet',\n",
       " 'trashy',\n",
       " 'trippy',\n",
       " 'visceral',\n",
       " 'warm'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moods = songs_df['moods'].tolist()\n",
    "moods_set = set(x for i in moods for x in i)\n",
    "moods_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest classifier bag of words ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [oppa, gangnam, style, gangnam, style, najeneu...\n",
       "1        [lately, i, ve, been, i, ve, been, losing, sle...\n",
       "2        [party, rock, yeah, woo, let, s, go, party, ro...\n",
       "3        [alagamun, lan, weh, wakun, heya, hanun, gon, ...\n",
       "4        [j, lo, the, other, side, out, my, mine, it, s...\n",
       "5        [today, i, don, t, feel, like, doing, anything...\n",
       "6        [there, s, a, fire, starting, in, my, heart, r...\n",
       "7        [i, threw, a, wish, in, the, well, don, t, ask...\n",
       "8        [now, and, then, i, think, of, when, we, were,...\n",
       "9        [don, t, know, what, for, you, re, turning, he...\n",
       "10       [nossa, nossa, assim, você, me, mata, ai, se, ...\n",
       "11       [shine, bright, like, a, diamond, shine, brigh...\n",
       "12       [do, you, ever, feel, like, a, plastic, bag, d...\n",
       "13       [oh, oh, woah, oh, oh, oh, oh, oh, oh, oh, oh,...\n",
       "14       [girl, my, body, don, t, lie, red, one, i, m, ...\n",
       "15       [ohh, ohh, ohh, ohh, ohh, oh, her, eyes, her, ...\n",
       "16       [it, s, our, party, we, can, do, what, we, wan...\n",
       "17       [i, heard, that, you, re, settled, down, that,...\n",
       "18       [yellow, diamonds, in, the, light, and, i, was...\n",
       "19       [this, one, is, for, the, boys, with, the, boo...\n",
       "20       [bring, the, action, when, you, hear, this, in...\n",
       "21       [me, not, working, hard, yea, right, picture, ...\n",
       "22                                                      []\n",
       "23       [i, hopped, off, the, plane, at, lax, with, my...\n",
       "24       [oh, na, na, what, s, my, name, oh, na, na, wh...\n",
       "25       [when, i, look, into, your, eyes, i, can, see,...\n",
       "26       [right, from, the, start, you, were, a, thief,...\n",
       "27       [seems, like, everybody, s, got, a, price, i, ...\n",
       "28       [you, know, masivo, we, run, the, world, vamos...\n",
       "29       [la, la, la, la, la, la, la, la, la, la, la, l...\n",
       "                               ...                        \n",
       "36703                                                   []\n",
       "36704                                                   []\n",
       "36705                                                   []\n",
       "36706                                                   []\n",
       "36707                                                   []\n",
       "36708                                                   []\n",
       "36709                                                   []\n",
       "36710                                                   []\n",
       "36711                                                   []\n",
       "36712                                                   []\n",
       "36713                                                   []\n",
       "36714                                                   []\n",
       "36715                                                   []\n",
       "36716    [thinking, of, you, that, s, all, i, seem, to,...\n",
       "36717                                                   []\n",
       "36718                                                   []\n",
       "36719                                                   []\n",
       "36720    [hey, hey, ladies, in, the, place, i, m, calli...\n",
       "36721                                                   []\n",
       "36722                                                   []\n",
       "36723    [yes, yeah, kayne, philadelphia, freeway, y, a...\n",
       "36724                                                   []\n",
       "36725    [sup, up, your, beer, and, collect, your, fags...\n",
       "36726                                                   []\n",
       "36727                                                   []\n",
       "36728                                                   []\n",
       "36729                                                   []\n",
       "36730                                                   []\n",
       "36731                                                   []\n",
       "36732                                                   []\n",
       "Name: lyrics_features, Length: 36733, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_df['lyrics_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = count_vect.fit_transform(songs_df['lyrics_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "moods = songs_df['moods']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bag_of_words\n",
    "y = moods\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'unknown'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-ae3c3a0f0e39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrfc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'log2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mrfc_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrfc_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_y_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_validate_y_class_weight\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_y_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    170\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[0;32m    171\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'unknown'"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=5, min_samples_split=2, max_features='log2')\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_predictions = rfc.predict(X_test)\n",
    "print(accuracy_score(y_test, rfc_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
